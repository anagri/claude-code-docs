url: https://docs.claude.com/en/docs/claude_api_primer.md

---

\# API usage primer for Claude > This guide is designed to give Claude the basics of using the Claude API. It gives explanation and examples of model IDs/the basic messages API, tool use, streaming, extended thinking, and nothing else. \# API usage primer for Claude > This guide is designed to give Claude the basics of using the Claude API. It gives explanation and examples of model IDs/the basic messages API, tool use, streaming, extended thinking, and nothing else. \#\# Models \`\`\` Smartest model: Claude Sonnet 4.5: claude-sonnet-4-5-20250929 For super-easy tasks: Claude Haiku 3.5: claude-3-5-haiku-20241022 \`\`\` \#\# Calling the API \#\#\# Basic request and response \`\`\`python import anthropic import os message = anthropic.Anthropic\(api\_key=os.environ.get\("ANTHROPIC\_API\_KEY"\)\).messages.create\( model="claude-sonnet-4-5", max\_tokens=1024, messages=\[ \{"role": "user", "content": "Hello, Claude"\} \] \) print\(message\) \`\`\` \`\`\`json \{ "id": "msg\_01XFDUDYJgAACzvnptvVoYEL", "type": "message", "role": "assistant", "content": \[ \{ "type": "text", "text": "Hello\!" \} \], "model": "claude-sonnet-4-5", "stop\_reason": "end\_turn", "stop\_sequence": null, "usage": \{ "input\_tokens": 12, "output\_tokens": 6 \} \} \`\`\` \#\#\# Multiple conversational turns The Messages API is stateless, which means that you always send the full conversational history to the API. You can use this pattern to build up a conversation over time. Earlier conversational turns don't necessarily need to actually originate from Claude — you can use synthetic \`assistant\` messages. \`\`\`python import anthropic message = anthropic.Anthropic\(\).messages.create\( model="claude-sonnet-4-5", max\_tokens=1024, messages=\[ \{"role": "user", "content": "Hello, Claude"\}, \{"role": "assistant", "content": "Hello\!"\}, \{"role": "user", "content": "Can you describe LLMs to me?"\} \], \) print\(message\) \`\`\` \#\#\# Putting words in Claude's mouth You can pre-fill part of Claude's response in the last position of the input messages list. This can be used to shape Claude's response. The example below uses \`"max\_tokens": 1\` to get a single multiple choice answer from Claude. \`\`\`python message = anthropic.Anthropic\(\).messages.create\( model="claude-sonnet-4-5", max\_tokens=1, messages=\[ \{"role": "user", "content": "What is latin for Ant? \(A\) Apoidea, \(B\) Rhopalocera, \(C\) Formicidae"\}, \{"role": "assistant", "content": "The answer is \("\} \] \) \`\`\` \#\#\# Vision Claude can read both text and images in requests. We support both \`base64\` and \`url\` source types for images, and the \`image/jpeg\`, \`image/png\`, \`image/gif\`, and \`image/webp\` media types. \`\`\`python import anthropic import base64 import httpx \# Option 1: Base64-encoded image image\_url = "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus\_flavomarginatus\_ant.jpg" image\_media\_type = "image/jpeg" image\_data = base64.standard\_b64encode\(httpx.get\(image\_url\).content\).decode\("utf-8"\) message = anthropic.Anthropic\(\).messages.create\( model="claude-sonnet-4-5", max\_tokens=1024, messages=\[ \{ "role": "user", "content": \[ \{ "type": "image", "source": \{ "type": "base64", "media\_type": image\_media\_type, "data": image\_data, \}, \}, \{ "type": "text", "text": "What is in the above image?" \} \], \} \], \) \# Option 2: URL-referenced image message\_from\_url = anthropic.Anthropic\(\).messages.create\( model="claude-sonnet-4-5", max\_tokens=1024, messages=\[ \{ "role": "user", "content": \[ \{ "type": "image", "source": \{ "type": "url", "url": "https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus\_flavomarginatus\_ant.jpg", \}, \}, \{ "type": "text", "text": "What is in the above image?" \} \], \} \], \) \`\`\` \#\# Extended Thinking Extended thinking can sometimes help Claude with very hard tasks. When it's enabled, temperature must be set to 1. Extended thinking is supported in the following models: \* Claude Opus 4.1 \(\`claude-opus-4-1-20250805\`\) \* Claude Opus 4 \(\`claude-opus-4-20250514\`\) \* Claude Sonnet 4.5 \(\`claude-sonnet-4-5-20250929\`\) \#\#\# How extended thinking works When extended thinking is turned on, Claude creates \`thinking\` content blocks where it outputs its internal reasoning. The API response will include \`thinking\` content blocks, followed by \`text\` content blocks. \`\`\`python import anthropic client = anthropic.Anthropic\(\) response = client.messages.create\( model="claude-sonnet-4-5", max\_tokens=16000, thinking=\{ "type": "enabled", "budget\_tokens": 10000 \}, messages=\[\{ "role": "user", "content": "Are there an infinite number of prime numbers such that n mod 4 == 3?" \}\] \) \# The response will contain summarized thinking blocks and text blocks for block in response.content: if block.type == "thinking": print\(f"\nThinking summary: \{block.thinking\}"\) elif block.type == "text": print\(f"\nResponse: \{block.text\}"\) \`\`\` The \`budget\_tokens\` parameter determines the maximum number of tokens Claude is allowed to use for its internal reasoning process. In Claude 4 models, this limit applies to full thinking tokens, and not to the summarized output. Larger budgets can improve response quality by enabling more thorough analysis for complex problems. One rule: the value of max\\\_tokens must be strictly greater than the value of budget\\\_tokens so that Claude has space to write its response after thinking is complete. \#\# Extended thinking with tool use Extended thinking can be used alongside tool use, allowing Claude to reason through tool selection and results processing. Important limitations: 1\. \*\*Tool choice limitation\*\*: Only supports \`tool\_choice: \{"type": "auto"\}\` \(default\) or \`tool\_choice: \{"type": "none"\}\`. 2\. \*\*Preserving thinking blocks\*\*: During tool use, you must pass \`thinking\` blocks back to the API for the last assistant message. \#\#\# Preserving thinking blocks \`\`\`python \# First request - Claude responds with thinking and tool request response = client.messages.create\( model="claude-sonnet-4-5", max\_tokens=16000, thinking=\{ "type": "enabled", "budget\_tokens": 10000 \}, tools=\[weather\_tool\], messages=\[ \{"role": "user", "content": "What's the weather in Paris?"\} \] \) \# Extract thinking block and tool use block thinking\_block = next\(\(block for block in response.content if block.type == 'thinking'\), None\) tool\_use\_block = next\(\(block for block in response.content if block.type == 'tool\_use'\), None\) \# Second request - Include thinking block and tool result continuation = client.messages.create\( model="claude-sonnet-4-5", max\_tokens=16000, thinking=\{ "type": "enabled", "budget\_tokens": 10000 \}, tools=\[weather\_tool\], messages=\[ \{"role": "user", "content": "What's the weather in Paris?"\}, \# Notice that the thinking\_block is passed in as well as the tool\_use\_block \{"role": "assistant", "content": \[thinking\_block, tool\_use\_block\]\}, \{"role": "user", "content": \[\{ "type": "tool\_result", "tool\_use\_id": tool\_use\_block.id, "content": f"Current temperature: \{weather\_data\['temperature'\]\}°F" \}\]\} \] \) \`\`\` \#\#\# Interleaved thinking Extended thinking with tool use in Claude 4 models supports interleaved thinking, which enables Claude to think between tool calls. To enable, add the beta header \`interleaved-thinking-2025-05-14\` to your API request. \`\`\`python response = client.beta.messages.create\( model="claude-sonnet-4-5", max\_tokens=16000, thinking=\{ "type": "enabled", "budget\_tokens": 10000 \}, tools=\[calculator\_tool, database\_tool\], messages=\[\{ "role": "user", "content": "What's the total revenue if we sold 150 units of product A at $50 each?" \}\], betas=\["interleaved-thinking-2025-05-14"\] \) \`\`\` With interleaved thinking and ONLY with interleaved thinking \(not regular extended thinking\), the \`budget\_tokens\` can exceed the \`max\_tokens\` parameter, as \`budget\_tokens\` in this case represents the total budget across all thinking blocks within one assistant turn. \#\# Tool Use \#\#\# Specifying client tools Client tools are specified in the \`tools\` top-level parameter of the API request. Each tool definition includes: | Parameter | Description | | :------------- | :-------------------------------------------------------------------------------------------------- | | \`name\` | The name of the tool. Must match the regex \`^\[a-zA-Z0-9\_-\]\{1,64\}$\`. | | \`description\` | A detailed plaintext description of what the tool does, when it should be used, and how it behaves. | | \`input\_schema\` | A \[JSON Schema\]\(https://json-schema.org/\) object defining the expected parameters for the tool. | \`\`\`json \{ "name": "get\_weather", "description": "Get the current weather in a given location", "input\_schema": \{ "type": "object", "properties": \{ "location": \{ "type": "string", "description": "The city and state, e.g. San Francisco, CA" \}, "unit": \{ "type": "string", "enum": \["celsius", "fahrenheit"\], "description": "The unit of temperature, either 'celsius' or 'fahrenheit'" \} \}, "required": \["location"\] \} \} \`\`\` \#\#\# Best practices for tool definitions \*\*Provide extremely detailed descriptions.\*\* This is by far the most important factor in tool performance. Your descriptions should explain every detail about the tool, including: \* What the tool does \* When it should be used \(and when it shouldn't\) \* What each parameter means and how it affects the tool's behavior \* Any important caveats or limitations Example of a good tool description: \`\`\`json \{ "name": "get\_stock\_price", "description": "Retrieves the current stock price for a given ticker symbol. The ticker symbol must be a valid symbol for a publicly traded company on a major US stock exchange like NYSE or NASDAQ. The tool will return the latest trade price in USD. It should be used when the user asks about the current or most recent price of a specific stock. It will not provide any other information about the stock or company.", "input\_schema": \{ "type": "object", "properties": \{ "ticker": \{ "type": "string", "description": "The stock ticker symbol, e.g. AAPL for Apple Inc." \} \}, "required": \["ticker"\] \} \} \`\`\` \#\# Controlling Claude's output \#\#\# Forcing tool use You can force Claude to use a specific tool by specifying the tool in the \`tool\_choice\` field: \`\`\`python tool\_choice = \{"type": "tool", "name": "get\_weather"\} \`\`\` When working with the tool\\\_choice parameter, we have four possible options: \* \`auto\` allows Claude to decide whether to call any provided tools or not \(default\). \* \`any\` tells Claude that it must use one of the provided tools. \* \`tool\` allows us to force Claude to always use a particular tool. \* \`none\` prevents Claude from using any tools. \#\#\# JSON output Tools do not necessarily need to be client functions — you can use tools anytime you want the model to return JSON output that follows a provided schema. \#\#\# Chain of thought When using tools, Claude will often show its "chain of thought", i.e. the step-by-step reasoning it uses to break down the problem and decide which tools to use. \`\`\`json \{ "role": "assistant", "content": \[ \{ "type": "text", "text": "To answer this question, I will: 1. Use the get\_weather tool to get the current weather in San Francisco. 2. Use the get\_time tool to get the current time in the America/Los\_Angeles timezone, which covers San Francisco, CA." \}, \{ "type": "tool\_use", "id": "toolu\_01A09q90qw90lq917835lq9", "name": "get\_weather", "input": \{ "location": "San Francisco, CA" \} \} \] \} \`\`\` \#\#\# Parallel tool use By default, Claude may use multiple tools to answer a user query. You can disable this behavior by setting \`disable\_parallel\_tool\_use=true\`. \#\# Handling tool use and tool result content blocks \#\#\# Handling results from client tools The response will have a \`stop\_reason\` of \`tool\_use\` and one or more \`tool\_use\` content blocks that include: \* \`id\`: A unique identifier for this particular tool use block. \* \`name\`: The name of the tool being used. \* \`input\`: An object containing the input being passed to the tool. When you receive a tool use response, you should: 1\. Extract the \`name\`, \`id\`, and \`input\` from the \`tool\_use\` block. 2\. Run the actual tool in your codebase corresponding to that tool name. 3\. Continue the conversation by sending a new message with a \`tool\_result\`: \`\`\`json \{ "role": "user", "content": \[ \{ "type": "tool\_result", "tool\_use\_id": "toolu\_01A09q90qw90lq917835lq9", "content": "15 degrees" \} \] \} \`\`\` \#\#\# Handling the \`max\_tokens\` stop reason If Claude's response is cut off due to hitting the \`max\_tokens\` limit during tool use, retry the request with a higher \`max\_tokens\` value. \#\#\# Handling the \`pause\_turn\` stop reason When using server tools like web search, the API may return a \`pause\_turn\` stop reason. Continue the conversation by passing the paused response back as-is in a subsequent request. \#\# Troubleshooting errors \#\#\# Tool execution error If the tool itself throws an error during execution, return the error message with \`"is\_error": true\`: \`\`\`json \{ "role": "user", "content": \[ \{ "type": "tool\_result", "tool\_use\_id": "toolu\_01A09q90qw90lq917835lq9", "content": "ConnectionError: the weather service API is not available \(HTTP 500\)", "is\_error": true \} \] \} \`\`\` \#\#\# Invalid tool name If Claude's attempted use of a tool is invalid \(e.g. missing required parameters\), try the request again with more-detailed \`description\` values in your tool definitions. \#\# Streaming Messages When creating a Message, you can set \`"stream": true\` to incrementally stream the response using server-sent events \(SSE\). \#\#\# Streaming with SDKs \`\`\`python import anthropic client = anthropic.Anthropic\(\) with client.messages.stream\( max\_tokens=1024, messages=\[\{"role": "user", "content": "Hello"\}\], model="claude-sonnet-4-5", \) as stream: for text in stream.text\_stream: print\(text, end="", flush=True\) \`\`\` \#\#\# Event types Each server-sent event includes a named event type and associated JSON data. Each stream uses the following event flow: 1\. \`message\_start\`: contains a \`Message\` object with empty \`content\`. 2\. A series of content blocks, each with \`content\_block\_start\`, one or more \`content\_block\_delta\` events, and \`content\_block\_stop\`. 3\. One or more \`message\_delta\` events, indicating top-level changes to the final \`Message\` object. 4\. A final \`message\_stop\` event. \*\*Warning\*\*: The token counts shown in the \`usage\` field of the \`message\_delta\` event are \*cumulative\*. \#\#\# Content block delta types \#\#\#\# Text delta \`\`\`json \{ "type": "content\_block\_delta", "index": 0, "delta": \{ "type": "text\_delta", "text": "Hello frien" \} \} \`\`\` \#\#\#\# Input JSON delta For \`tool\_use\` content blocks, deltas are \*partial JSON strings\*: \`\`\`json \{"type": "content\_block\_delta","index": 1,"delta": \{"type": "input\_json\_delta","partial\_json": "\{\"location\": \"San Fra”\}\}\} \`\`\` \#\#\#\# Thinking delta When using extended thinking with streaming: \`\`\`json \{ "type": "content\_block\_delta", "index": 0, "delta": \{ "type": "thinking\_delta", "thinking": "Let me solve this step by step..." \} \} \`\`\` \#\#\# Basic streaming request example \`\`\`json event: message\_start data: \{"type": "message\_start", "message": \{"id": "msg\_1nZdL29xx5MUA1yADyHTEsnR8uuvGzszyY", "type": "message", "role": "assistant", "content": \[\], "model": "claude-sonnet-4-5", "stop\_reason": null, "stop\_sequence": null, "usage": \{"input\_tokens": 25, "output\_tokens": 1\}\}\} event: content\_block\_start data: \{"type": "content\_block\_start", "index": 0, "content\_block": \{"type": "text", "text": ""\}\} event: content\_block\_delta data: \{"type": "content\_block\_delta", "index": 0, "delta": \{"type": "text\_delta", "text": "Hello"\}\} event: content\_block\_delta data: \{"type": "content\_block\_delta", "index": 0, "delta": \{"type": "text\_delta", "text": "\!"\}\} event: content\_block\_stop data: \{"type": "content\_block\_stop", "index": 0\} event: message\_delta data: \{"type": "message\_delta", "delta": \{"stop\_reason": "end\_turn", "stop\_sequence":null\}, "usage": \{"output\_tokens": 15\}\} event: message\_stop data: \{"type": "message\_stop"\} \`\`\`
